{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "from seaborn import color_palette\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Hyperparameters\n",
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_AHCHORS = [(10, 13), (16,30), (33,23),\n",
    "            (30,61), (62,45), (59,119),\n",
    "            (116,90), (156,198), (373,326)]\n",
    "_MODEL_SIZE = (416,416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Definition\n",
    "#batch normalization and leaky ReLU\n",
    "\n",
    "def batch_norm(inputs, training, data_format):\n",
    "    return tf.layers.batch_normalization(\n",
    "        inputs = inputs, axis = 1 if data_format == 'channels_first' else 3,\n",
    "        momentum = _BATCH_NORM_DECAY, epsilon = _BATCH_NORM_EPSILON,\n",
    "        scale = True, training = training\n",
    "    )\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg \n",
    "    if data_format == 'channels_first':\n",
    "        padded_inputs = tf.pad(inputs, [[0,0], [0,0],\n",
    "                                        [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0,0],\n",
    "                                        [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end],\n",
    "                                        [0,0]])\n",
    "    return padded_inputs\n",
    "\n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides = 1):\n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "    return tf.layers.conv2d(\n",
    "        inputs = inputs, filters = filters, kernel_size = kernel_size,\n",
    "        strides = strides, padding = ('SAME' if strides == 1 else 'VAILD'),\n",
    "        use_bias = False, data_format = data_format\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction: Darknet-53\n",
    "\n",
    "def darknet53_residual_block(inputs, filters, training, data_format, strides = 1):\n",
    "    shortcut = inputs \n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = filters, kernel_size = 1,\n",
    "        strides = strides, data_format=  data_format\n",
    "    )\n",
    "    inputs = batch_norm( inputs, training = training, data_format= data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha = _LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = 2 * filters, kernel_size=3, strides= strides,\n",
    "        data_format= data_format\n",
    "    )\n",
    "    inputs = batch_norm(inputs, training= training, data_format= data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    inputs += shortcut\n",
    "    return inputs \n",
    "\n",
    "def darknet53(inputs, training, data_format):\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters= 32, kernel_size= 3,\n",
    "        data_format = data_format\n",
    "    )\n",
    "    inputs = batch_norm (inputs, training = training, data_format= data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = 64, kernel_size= 3, strides= 2, data_format= data_format\n",
    "    )\n",
    "    inputs = batch_norm(inputs, training = training, data_format= data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "    inputs = darknet53_residual_block(inputs, filters = 32, training= training,data_format=data_format)\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters= 128, kernel_size= 3, strides= 2, data_format= data_format\n",
    "    )\n",
    "    inputs = batch_norm(inputs, training= training, data_format= data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(\n",
    "            inputs, filters = 128,\n",
    "            training = training,\n",
    "            data_format = data_format\n",
    "        )\n",
    "\n",
    "        route1 = inputs \n",
    "        inputs = conv2d_fixed_padding(\n",
    "            inputs, filters = 512, kernel_size=3,\n",
    "            strides = 2, data_format = data_format\n",
    "        )\n",
    "        inputs = batch_norm(inputs, training = training, data_format = data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(\n",
    "            inputs, filters = 256, training= training, data_format=data_format\n",
    "        )\n",
    "        route2 = inputs \n",
    "        inputs = conv2d_fixed_padding(\n",
    "            inputs, filters = 1024, kernel_size= 3,\n",
    "            strides = 2, data_format = data_format\n",
    "        )\n",
    "        inputs = batch_norm(inputs, training= training, data_format=data_format)\n",
    "        inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    for _ in range(4):\n",
    "        inputs = darknet53_residual_block(\n",
    "            inputs, filters=512,\n",
    "            training = training,\n",
    "            data_format = data_format\n",
    "        )\n",
    "\n",
    "    return route1, route2, inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution Layers\n",
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = filters, kernel_size=1,data_format=data_format\n",
    "    )\n",
    "\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = 2*filters, kernel_size=3,data_format=data_format\n",
    "    )\n",
    "\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = filters, kernel_size=1,data_format=data_format\n",
    "    )\n",
    "\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = 2*filters, kernel_size=3,data_format=data_format\n",
    "    )\n",
    "\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = filters, kernel_size=1,data_format=data_format\n",
    "    )\n",
    "\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    route = inputs \n",
    "    \n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters = 2*filters, kernel_size=3,data_format=data_format\n",
    "    )\n",
    "\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha= _LEAKY_RELU)\n",
    "\n",
    "    return route, inputs \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Layers\n",
    "\n",
    "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
    "    n_anchors = len(anchors)\n",
    "\n",
    "    inputs = tf.layers.conv2d(inputs, filters = n_anchors * (5 + n_classes),\n",
    "                              kernel_size = 1, strides = 1, use_bias = True,\n",
    "                              data_format = data_format)\n",
    "    \n",
    "    shape = inputs.get_shape().as_list()\n",
    "\n",
    "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]\n",
    "\n",
    "if data_format == 'channels_first':\n",
    "    inputs = tf.transpose(inputs, [0,2,3,1])\n",
    "inputs = tf.reshape(\n",
    "    inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1],\n",
    "             5 + n_classes]\n",
    ")\n",
    "\n",
    "strides = (img_size[0] // grid_shape[0], img_size[1]// grid_shape[1])\n",
    "\n",
    "box_centers, box_shapes, confidence, classes = tf.split(inputs, [2,2,1,n_classes] , axis = -1)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
